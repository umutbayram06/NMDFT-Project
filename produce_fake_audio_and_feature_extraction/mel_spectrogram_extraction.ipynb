{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acb73039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nChatGPT chat histories that helped me\\nhttps://chatgpt.com/share/686a7921-3030-8005-9b79-65d7198f586c\\nhttps://chatgpt.com/share/686a7813-b100-8005-ad6b-add8985b711c\\nhttps://chatgpt.com/share/686a7871-638c-8005-89d6-78e0567f5124\\nhttps://chatgpt.com/share/686a790c-4ce8-8005-b5ae-4bb3fc107c7e\\nhttps://chatgpt.com/share/686a7885-1654-8005-8078-30985754675e\\nhttps://chatgpt.com/share/686a7899-f834-8005-a729-877113dc0878\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "ChatGPT chat histories that helped me\n",
    "https://chatgpt.com/share/686a7921-3030-8005-9b79-65d7198f586c\n",
    "https://chatgpt.com/share/686a7813-b100-8005-ad6b-add8985b711c\n",
    "https://chatgpt.com/share/686a7871-638c-8005-89d6-78e0567f5124\n",
    "https://chatgpt.com/share/686a790c-4ce8-8005-b5ae-4bb3fc107c7e\n",
    "https://chatgpt.com/share/686a7885-1654-8005-8078-30985754675e\n",
    "https://chatgpt.com/share/686a7899-f834-8005-a729-877113dc0878\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "529d8ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac2b03d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "sample_rate = 22050\n",
    "n_fft = 1024\n",
    "hop_length = 512\n",
    "n_mels = 128\n",
    "target_duration = 5  # seconds\n",
    "target_length = sample_rate * target_duration  # 110250\n",
    "timesteps = 36\n",
    "frames_per_timestep = 6\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6c8fef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_transform = torchaudio.transforms.MelSpectrogram(\n",
    "    sample_rate=sample_rate,\n",
    "    n_fft=n_fft,\n",
    "    hop_length=hop_length,\n",
    "    n_mels=n_mels,\n",
    "    window_fn=torch.hann_window\n",
    ").to(device)\n",
    "\n",
    "def find_audio_files_with_label(root_dir):\n",
    "    files = []\n",
    "    labels = []\n",
    "    for label_dir, label in [('real', 0), ('fake', 1)]:\n",
    "        full_dir = os.path.join(root_dir, label_dir)\n",
    "        for root, _, filenames in os.walk(full_dir):\n",
    "            for fname in filenames:\n",
    "                if fname.lower().endswith(('.wav', '.mp3')):\n",
    "                    files.append(os.path.join(root, fname))\n",
    "                    labels.append(label)\n",
    "    return files, labels\n",
    "\n",
    "def load_audio(filepath, target_sr=sample_rate):\n",
    "    waveform, sr = torchaudio.load(filepath)\n",
    "    if sr != target_sr:\n",
    "        waveform = torchaudio.functional.resample(waveform, sr, target_sr)\n",
    "    return waveform\n",
    "\n",
    "def fix_audio_length(waveform, target_length):\n",
    "    length = waveform.shape[1]\n",
    "    if length < target_length:\n",
    "        pad_amount = target_length - length\n",
    "        waveform = torch.nn.functional.pad(waveform, (0, pad_amount))\n",
    "    else:\n",
    "        waveform = waveform[:, :target_length]\n",
    "    return waveform\n",
    "\n",
    "def normalize(x):\n",
    "    return (x - x.min()) / (x.max() - x.min() + 1e-6)\n",
    "\n",
    "def reshape_mel(mel):\n",
    "    total_frames = mel.shape[1]\n",
    "    expected_frames = timesteps * frames_per_timestep\n",
    "    if total_frames < expected_frames:\n",
    "        mel = np.pad(mel, ((0, 0), (0, expected_frames - total_frames)))\n",
    "    else:\n",
    "        mel = mel[:, :expected_frames]\n",
    "    mel = mel.reshape(n_mels, timesteps, frames_per_timestep)\n",
    "    mel = mel.transpose(1, 0, 2)  # (timesteps, height, width)\n",
    "    mel = mel[..., np.newaxis]   # (timesteps, height, width, channels)\n",
    "    return mel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d9ae14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing audio files: 100%|██████████| 20046/20046 [01:48<00:00, 185.06it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_dir = 'test_dataset'\n",
    "\n",
    "audio_files, labels = find_audio_files_with_label(dataset_dir)\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for i, file in enumerate(tqdm(audio_files, desc=\"Processing audio files\")):\n",
    "    waveform = load_audio(file).to(device)\n",
    "    waveform = fix_audio_length(waveform, target_length)\n",
    "    mel_spec = mel_transform(waveform).squeeze(0).cpu().numpy()\n",
    "    mel_spec = normalize(mel_spec)\n",
    "    mel_spec = reshape_mel(mel_spec)\n",
    "    X.append(mel_spec)\n",
    "    y.append(labels[i])\n",
    "\n",
    "X = np.array(X)  # Shape: (samples, timesteps, height, width, channels)\n",
    "y = np.array(y)\n",
    "\n",
    "np.save('mel_spectrograms_test.npy', X)\n",
    "np.save('labels_test.npy', y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
